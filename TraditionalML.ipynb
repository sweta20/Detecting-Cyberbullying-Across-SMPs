{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/usr/local/lib/python2.7/site-packages/sklearn/grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('/usr/local/bin/python2.7')\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import os, sys, getopt, pickle, csv, sklearn\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.metrics import classification_report, f1_score, accuracy_score, confusion_matrix, make_scorer, recall_score, precision_score, classification_report, precision_recall_fscore_support\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.ensemble  import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score, train_test_split, KFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.utils import shuffle\n",
    "from textblob import TextBlob\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "from collections import Counter\n",
    "import argparse\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import roc_auc_score    \n",
    "import preprocessor as p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "models = [ 'svm', 'naive', 'lr', 'random_forest']\n",
    "NO_OF_FOLDS = 10\n",
    "MODEL_TYPE = \"all\"\n",
    "HASH_REMOVE = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_data(filename):\n",
    "    data = pickle.load(open(filename, 'rb'))\n",
    "    x_text = []\n",
    "    labels = []\n",
    "    for i in range(len(data)):\n",
    "        if(HASH_REMOVE):\n",
    "            x_text.append(p.tokenize((data[i]['text']).encode('utf-8')))\n",
    "        else:\n",
    "            x_text.append(data[i]['text'])\n",
    "        labels.append(data[i]['label'])\n",
    "    return x_text,labels\n",
    "\n",
    "def get_filename(dataset):\n",
    "    global N_CLASS, HASH_REMOVE\n",
    "    if(dataset==\"twitter\"):\n",
    "        filename = \"data/twitter_data.pkl\"\n",
    "        N_CLASS = 3\n",
    "        HASH_REMOVE = False\n",
    "    elif(dataset==\"formspring\"):\n",
    "        N_CLASS = 2\n",
    "        filename = \"data/formspring_data.pkl\"\n",
    "        HASH_REMOVE = False\n",
    "    elif(dataset==\"wiki\"):\n",
    "        N_CLASS = 2\n",
    "        filename = \"data/wiki_data.pkl\"\n",
    "        HASH_REMOVE = False\n",
    "    return filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_scores(y_true, y_pred):\n",
    "#     if(data==\"wiki\"):\n",
    "#         auc = roc_auc_score(y_true,y_pred)\n",
    "#         print('Test ROC AUC: %.3f' %auc)\n",
    "#     print(\":: Confusion Matrix\")\n",
    "#     print(confusion_matrix(y_true, y_pred))\n",
    "#     print(\":: Classification Report\")\n",
    "#     print(classification_report(y_true, y_pred))\n",
    "    return np.array([ \n",
    "            precision_score(y_true, y_pred, average=None), \n",
    "            recall_score(y_true, y_pred,  average=None),\n",
    "            f1_score(y_true, y_pred, average=None)])\n",
    "    \n",
    "def print_scores(scores):\n",
    "    for i in range(N_CLASS):\n",
    "        if(i!=0):\n",
    "            print \"Precision Class %d (avg): %0.3f (+/- %0.3f)\" % (i,scores[:, i].mean(), scores[:, i].std() * 2)\n",
    "            print \"Recall Class %d (avg): %0.3f (+/- %0.3f)\" % (i,scores[:,  N_CLASS+i].mean(), scores[:,N_CLASS+i].std() * 2)\n",
    "            print \"F1_score Class %d (avg): %0.3f (+/- %0.3f)\" % (i,scores[:, N_CLASS*2+i].mean(), scores[:,  N_CLASS*2+i].std() * 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def classification_model(X, Y, model_type):\n",
    "    X, Y = shuffle(X, Y, random_state=42)\n",
    "    print \"Model Type:\", model_type\n",
    "    kf = KFold(n_splits=NO_OF_FOLDS)\n",
    "    scores = []\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        Y = np.asarray(Y)\n",
    "        model = get_model(model_type)\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = Y[train_index], Y[test_index]\n",
    "        model.fit(X_train,y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        curr_scores = get_scores(y_test, y_pred)\n",
    "        scores.append(np.hstack(curr_scores))\n",
    "    print_scores(np.array(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_model(m_type):\n",
    "    if m_type == 'lr':\n",
    "        logreg = LogisticRegression(class_weight=\"balanced\")\n",
    "    elif m_type == 'naive':\n",
    "        logreg =  MultinomialNB()\n",
    "    elif m_type == \"random_forest\":\n",
    "        logreg = RandomForestClassifier(n_estimators=100, n_jobs=-1)\n",
    "    elif m_type == \"svm\":\n",
    "        logreg = LinearSVC(class_weight=\"balanced\")\n",
    "    else:\n",
    "        print \"ERROR: Please specify a correst model\"\n",
    "        return None\n",
    "    return logreg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(x_text, labels, MODEL_TYPE):\n",
    "    \n",
    "    if(WORD):\n",
    "        print(\"Using word based features\")\n",
    "        bow_transformer = CountVectorizer(analyzer=\"word\",max_features = 10000,stop_words='english').fit(x_text)\n",
    "        comments_bow = bow_transformer.transform(x_text)\n",
    "        tfidf_transformer = TfidfTransformer(norm = 'l2').fit(comments_bow)\n",
    "        comments_tfidf = tfidf_transformer.transform(comments_bow)\n",
    "        features = comments_tfidf\n",
    "    else: \n",
    "        print(\"Using char n-grams based features\")\n",
    "        bow_transformer = CountVectorizer(max_features = 10000, ngram_range = (1,2)).fit(x_text)\n",
    "        comments_bow = bow_transformer.transform(x_text)\n",
    "        tfidf_transformer = TfidfTransformer(norm = 'l2').fit(comments_bow)\n",
    "        comments_tfidf = tfidf_transformer.transform(comments_bow)\n",
    "        features = comments_tfidf\n",
    "    \n",
    "    if(data == \"twitter\"):\n",
    "        dict1 = {'racism':0,'sexism':1,'none':2}\n",
    "        labels = np.array([dict1[b] for b in labels])\n",
    "    \n",
    "    from collections import Counter\n",
    "    print(Counter(labels))\n",
    "    \n",
    "    if(MODEL_TYPE != \"all\"):\n",
    "        classification_model(features, labels, MODEL_TYPE)\n",
    "    else:\n",
    "        for model_type in models:\n",
    "            classification_model(features, labels, model_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded!\n",
      "Using char n-grams based features\n",
      "Counter({0: 11997, 1: 776})\n",
      "Model Type: svm\n",
      "Precision Class 1 (avg): 0.466 (+/- 0.109)\n",
      "Recall Class 1 (avg): 0.503 (+/- 0.122)\n",
      "F1_score Class 1 (avg): 0.483 (+/- 0.104)\n",
      "Model Type: naive\n",
      "Precision Class 1 (avg): 0.850 (+/- 0.640)\n",
      "Recall Class 1 (avg): 0.015 (+/- 0.015)\n",
      "F1_score Class 1 (avg): 0.030 (+/- 0.028)\n",
      "Model Type: lr\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python2.7/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision Class 1 (avg): 0.410 (+/- 0.099)\n",
      "Recall Class 1 (avg): 0.626 (+/- 0.131)\n",
      "F1_score Class 1 (avg): 0.495 (+/- 0.104)\n",
      "Model Type: random_forest\n",
      "Precision Class 1 (avg): 0.784 (+/- 0.194)\n",
      "Recall Class 1 (avg): 0.173 (+/- 0.051)\n",
      "F1_score Class 1 (avg): 0.281 (+/- 0.064)\n"
     ]
    }
   ],
   "source": [
    "data = \"formspring\"\n",
    "WORD =  False\n",
    "x_text, labels = load_data(get_filename(data)) \n",
    "print (\"Data loaded!\")\n",
    "train(x_text, labels, MODEL_TYPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded!\n",
      "Using word based features\n",
      "Counter({0: 11997, 1: 776})\n",
      "Model Type: svm\n",
      "Precision Class 1 (avg): 0.415 (+/- 0.089)\n",
      "Recall Class 1 (avg): 0.525 (+/- 0.132)\n",
      "F1_score Class 1 (avg): 0.463 (+/- 0.100)\n",
      "Model Type: naive\n",
      "Precision Class 1 (avg): 0.575 (+/- 0.950)\n",
      "Recall Class 1 (avg): 0.013 (+/- 0.029)\n",
      "F1_score Class 1 (avg): 0.025 (+/- 0.055)\n",
      "Model Type: lr\n",
      "Precision Class 1 (avg): 0.407 (+/- 0.079)\n",
      "Recall Class 1 (avg): 0.617 (+/- 0.127)\n",
      "F1_score Class 1 (avg): 0.489 (+/- 0.084)\n",
      "Model Type: random_forest\n",
      "Precision Class 1 (avg): 0.726 (+/- 0.243)\n",
      "Recall Class 1 (avg): 0.162 (+/- 0.069)\n",
      "F1_score Class 1 (avg): 0.263 (+/- 0.099)\n"
     ]
    }
   ],
   "source": [
    "data = \"formspring\"\n",
    "WORD = True\n",
    "x_text, labels = load_data(get_filename(data)) \n",
    "print (\"Data loaded!\")\n",
    "train(x_text, labels, MODEL_TYPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded!\n",
      "Using char n-grams based features\n",
      "Counter({2: 11036, 1: 3117, 0: 1937})\n",
      "Model Type: svm\n",
      "Precision Class 1 (avg): 0.786 (+/- 0.055)\n",
      "Recall Class 1 (avg): 0.736 (+/- 0.067)\n",
      "F1_score Class 1 (avg): 0.759 (+/- 0.040)\n",
      "Precision Class 2 (avg): 0.891 (+/- 0.026)\n",
      "Recall Class 2 (avg): 0.896 (+/- 0.020)\n",
      "F1_score Class 2 (avg): 0.894 (+/- 0.013)\n",
      "Model Type: naive\n",
      "Precision Class 1 (avg): 0.910 (+/- 0.056)\n",
      "Recall Class 1 (avg): 0.455 (+/- 0.089)\n",
      "F1_score Class 1 (avg): 0.605 (+/- 0.082)\n",
      "Precision Class 2 (avg): 0.804 (+/- 0.025)\n",
      "Recall Class 2 (avg): 0.963 (+/- 0.008)\n",
      "F1_score Class 2 (avg): 0.876 (+/- 0.014)\n",
      "Model Type: lr\n",
      "Precision Class 1 (avg): 0.825 (+/- 0.048)\n",
      "Recall Class 1 (avg): 0.641 (+/- 0.084)\n",
      "F1_score Class 1 (avg): 0.721 (+/- 0.059)\n",
      "Precision Class 2 (avg): 0.869 (+/- 0.026)\n",
      "Recall Class 2 (avg): 0.915 (+/- 0.012)\n",
      "F1_score Class 2 (avg): 0.891 (+/- 0.011)\n",
      "Model Type: random_forest\n",
      "Precision Class 1 (avg): 0.898 (+/- 0.039)\n",
      "Recall Class 1 (avg): 0.560 (+/- 0.069)\n",
      "F1_score Class 1 (avg): 0.689 (+/- 0.056)\n",
      "Precision Class 2 (avg): 0.842 (+/- 0.030)\n",
      "Recall Class 2 (avg): 0.950 (+/- 0.009)\n",
      "F1_score Class 2 (avg): 0.893 (+/- 0.017)\n"
     ]
    }
   ],
   "source": [
    "data = \"twitter\"\n",
    "WORD = False\n",
    "x_text, labels = load_data(get_filename(data)) \n",
    "print (\"Data loaded!\")\n",
    "train(x_text, labels, MODEL_TYPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded!\n",
      "Using word based features\n",
      "Counter({2: 11036, 1: 3117, 0: 1937})\n",
      "Model Type: svm\n",
      "Precision Class 1 (avg): 0.803 (+/- 0.044)\n",
      "Recall Class 1 (avg): 0.744 (+/- 0.052)\n",
      "F1_score Class 1 (avg): 0.772 (+/- 0.037)\n",
      "Precision Class 2 (avg): 0.893 (+/- 0.023)\n",
      "Recall Class 2 (avg): 0.901 (+/- 0.018)\n",
      "F1_score Class 2 (avg): 0.897 (+/- 0.009)\n",
      "Model Type: naive\n",
      "Precision Class 1 (avg): 0.904 (+/- 0.035)\n",
      "Recall Class 1 (avg): 0.469 (+/- 0.056)\n",
      "F1_score Class 1 (avg): 0.617 (+/- 0.051)\n",
      "Precision Class 2 (avg): 0.806 (+/- 0.022)\n",
      "Recall Class 2 (avg): 0.963 (+/- 0.007)\n",
      "F1_score Class 2 (avg): 0.877 (+/- 0.011)\n",
      "Model Type: lr\n",
      "Precision Class 1 (avg): 0.832 (+/- 0.039)\n",
      "Recall Class 1 (avg): 0.663 (+/- 0.083)\n",
      "F1_score Class 1 (avg): 0.738 (+/- 0.062)\n",
      "Precision Class 2 (avg): 0.875 (+/- 0.026)\n",
      "Recall Class 2 (avg): 0.916 (+/- 0.012)\n",
      "F1_score Class 2 (avg): 0.895 (+/- 0.012)\n",
      "Model Type: random_forest\n",
      "Precision Class 1 (avg): 0.873 (+/- 0.043)\n",
      "Recall Class 1 (avg): 0.640 (+/- 0.073)\n",
      "F1_score Class 1 (avg): 0.738 (+/- 0.058)\n",
      "Precision Class 2 (avg): 0.866 (+/- 0.028)\n",
      "Recall Class 2 (avg): 0.936 (+/- 0.011)\n",
      "F1_score Class 2 (avg): 0.900 (+/- 0.016)\n"
     ]
    }
   ],
   "source": [
    "data = \"twitter\"\n",
    "WORD = True\n",
    "x_text, labels = load_data(get_filename(data)) \n",
    "print (\"Data loaded!\")\n",
    "train(x_text, labels, MODEL_TYPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded!\n",
      "Using char n-grams based features\n",
      "Counter({0: 102274, 1: 13590})\n",
      "Model Type: svm\n",
      "Precision Class 1 (avg): 0.591 (+/- 0.025)\n",
      "Recall Class 1 (avg): 0.823 (+/- 0.019)\n",
      "F1_score Class 1 (avg): 0.688 (+/- 0.018)\n",
      "Model Type: naive\n",
      "Precision Class 1 (avg): 0.839 (+/- 0.010)\n",
      "Recall Class 1 (avg): 0.554 (+/- 0.028)\n",
      "F1_score Class 1 (avg): 0.667 (+/- 0.021)\n",
      "Model Type: lr\n",
      "Precision Class 1 (avg): 0.602 (+/- 0.024)\n",
      "Recall Class 1 (avg): 0.845 (+/- 0.022)\n",
      "F1_score Class 1 (avg): 0.703 (+/- 0.017)\n",
      "Model Type: random_forest\n",
      "Precision Class 1 (avg): 0.886 (+/- 0.012)\n",
      "Recall Class 1 (avg): 0.550 (+/- 0.030)\n",
      "F1_score Class 1 (avg): 0.678 (+/- 0.023)\n"
     ]
    }
   ],
   "source": [
    "data = \"wiki\"\n",
    "WORD = False\n",
    "x_text, labels = load_data(get_filename(data)) \n",
    "print (\"Data loaded!\")\n",
    "train(x_text, labels, MODEL_TYPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded!\n",
      "Using word based features\n",
      "Counter({0: 102274, 1: 13590})\n",
      "Model Type: svm\n",
      "Precision Class 1 (avg): 0.591 (+/- 0.025)\n",
      "Recall Class 1 (avg): 0.819 (+/- 0.028)\n",
      "F1_score Class 1 (avg): 0.686 (+/- 0.020)\n",
      "Model Type: naive\n",
      "Precision Class 1 (avg): 0.898 (+/- 0.016)\n",
      "Recall Class 1 (avg): 0.521 (+/- 0.036)\n",
      "F1_score Class 1 (avg): 0.659 (+/- 0.028)\n",
      "Model Type: lr\n",
      "Precision Class 1 (avg): 0.620 (+/- 0.027)\n",
      "Recall Class 1 (avg): 0.834 (+/- 0.024)\n",
      "F1_score Class 1 (avg): 0.711 (+/- 0.021)\n",
      "Model Type: random_forest\n",
      "Precision Class 1 (avg): 0.810 (+/- 0.024)\n",
      "Recall Class 1 (avg): 0.662 (+/- 0.030)\n",
      "F1_score Class 1 (avg): 0.729 (+/- 0.025)\n"
     ]
    }
   ],
   "source": [
    "data = \"wiki\"\n",
    "WORD = True\n",
    "x_text, labels = load_data(get_filename(data)) \n",
    "print (\"Data loaded!\")\n",
    "train(x_text, labels, MODEL_TYPE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
